{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 5: Boosting\n",
    "\n",
    "## Submission by: Mark Preston\n",
    "\n",
    "This week, I'll be using a census data set to classify individual adults that make above and below 50K in a given year. The set includes a variety of individual traits for a person, including age, race, work details, educational attainment, and family background, to name a few. Since the data set doesn't include a header here, I've manually added it during the data loading using the `names` parameter. The target variable is whether an individual will make above or below 50K in a year, which is just a binary flag I've names income_bracket in the set.\n",
    "\n",
    "### Data Processing\n",
    "\n",
    "Beginning the analysis, the main data processing stems from needing to download the data from the UCI Machine Learning Repository. The data should be relatively clean coming from a well known data source but, I did need to add in header names using the set's data dictionary (https://archive.ics.uci.edu/ml/datasets/Adult). With the basic processing, I've loaded the set in and evaluated the shape below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The census data has 32561 rows and 15 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_census = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", \n",
    "    header = None, \n",
    "    skipinitialspace = True, \n",
    "    names = [\"age\", \"work_class\", \"fnlwgt\", \"education\", \"edu_years\", \"marital_status\", \n",
    "             \"occupation\", \"relationship\", \"race\", \"sex\", \"capital_gain\", \"capital_loss\",\n",
    "             \"hours_per_week\", \"native_country\", \"income_bracket\"]\n",
    ")\n",
    "\n",
    "print(\"The census data has\", \n",
    "      adult_census.shape[0], \"rows and\", \n",
    "      adult_census.shape[1],  \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with data from the UCI usually means a clean set. To verify this though, I've counted the null values in the set below. As seen, there are no null values so the set is clean and well maintained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_null_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_class</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fnlwgt</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edu_years</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital_status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_gain</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_loss</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours_per_week</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native_country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income_bracket</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                is_null_count\n",
       "age                         0\n",
       "work_class                  0\n",
       "fnlwgt                      0\n",
       "education                   0\n",
       "edu_years                   0\n",
       "marital_status              0\n",
       "occupation                  0\n",
       "relationship                0\n",
       "race                        0\n",
       "sex                         0\n",
       "capital_gain                0\n",
       "capital_loss                0\n",
       "hours_per_week              0\n",
       "native_country              0\n",
       "income_bracket              0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"is_null_count\": adult_census.isnull().sum()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another small update, I'm also dropping the fnlwgt column as well. With this, there are 14 columns remaining for the modelling work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated census data has 32561 rows and 14 columns\n"
     ]
    }
   ],
   "source": [
    "adult_census = adult_census.drop(columns=[\"fnlwgt\"])\n",
    "\n",
    "print(\"The updated census data has\", \n",
    "      adult_census.shape[0], \"rows and\", \n",
    "      adult_census.shape[1],  \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final formal update to the set is replacing the categorical income bracket labels with numeric values. For this,  $50K \\leq$ becomes a zero while over 50K a one. To validate that the replacement worked, I've done a value count for each level in the variable. As seen, the labels are now numeric. The set has about 76% of individuals $50K \\leq$ yearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   income_count\n",
       "0         24720\n",
       "1          7841"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_census[\"income_bracket\"] = adult_census[\"income_bracket\"].replace([\"<=50K\", \">50K\"], [0, 1])\n",
    "\n",
    "pd.DataFrame({\"income_count\": adult_census[\"income_bracket\"].value_counts()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the cleaning complete, I've split the data into training and test for the modelling portion. I've elected to use a 70/30 split, which is confirmed by the dimensional prinout from the new sets. As an additional update, I've used dummy coding for the categorical features. This expands the set to 107 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set rows: 22792 which is 70.0 percent of total records\n",
      "Test set rows: 9769 which is 30.0 percent of total records\n",
      "Training set columns: 107\n",
      "Test set columns: 107\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "predictors = adult_census.drop(columns=[\"income_bracket\"], axis=1)\n",
    "\n",
    "X_encoded = pd.get_dummies(predictors)\n",
    "\n",
    "outcome = adult_census[[\"income_bracket\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, outcome, random_state=1017, test_size=.3)\n",
    "\n",
    "print(\n",
    "\"Training set rows:\", X_train.shape[0], \"which is\", \n",
    "    np.round(X_train.shape[0] / adult_census.shape[0] * 100), \n",
    "    \"percent of total records\"\n",
    ")\n",
    "\n",
    "print(\n",
    "\"Test set rows:\", X_test.shape[0], \"which is\", \n",
    "    np.round(X_test.shape[0] / adult_census.shape[0] * 100),\n",
    "    \"percent of total records\"\n",
    ")\n",
    "\n",
    "print(\"Training set columns:\", X_train.shape[1])\n",
    "print(\"Test set columns:\", X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14561</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11939</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29771</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15006</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27503</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       income_bracket\n",
       "14561               0\n",
       "11939               0\n",
       "29771               1\n",
       "15006               1\n",
       "27503               0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Random Forest Classifier\n",
    "\n",
    "The baseline random forest is an okay starting point for getting a better understanding of the prediction task. That said, without any tuning parameters, especially max depth, the model should be very overfit. There's still some value to using it as a starting point though. Below, I've fit the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=1017, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier(random_state=1017)\n",
    "\n",
    "rf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial few predictions look promising enough. The classifier shows all five records are accurate here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>class_pred</th>\n",
       "      <th>over_50_prob</th>\n",
       "      <th>under_50_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8584</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15201</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15160</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11843</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       actual  class_pred  over_50_prob  under_50_prob\n",
       "8584        1           1           0.7            0.3\n",
       "16101       0           0           0.0            1.0\n",
       "15201       0           0           0.4            0.6\n",
       "15160       1           1           1.0            0.0\n",
       "11843       0           0           0.0            1.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_rf_preds = pd.DataFrame({\n",
    "    \"actual\": y_test[\"income_bracket\"],\n",
    "    \"class_pred\": rf.predict(X_test),\n",
    "    \"under_50_prob\": rf.predict_proba(X_test)[:,0],\n",
    "    \"over_50_prob\": rf.predict_proba(X_test)[:,1]\n",
    "})\n",
    "\n",
    "baseline_rf_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows a reasonable first result. I'm not in tune with the business or social research context but, I'm assuming the idea is to have a good balanced accuracy here. The under 50 predictions are more reasonable here but, the true over 50 values still seem good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Under 50</th>\n",
       "      <th>Over 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Under 50</th>\n",
       "      <td>6793</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Over 50</th>\n",
       "      <td>941</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Under 50  Over 50\n",
       "Under 50      6793      635\n",
       "Over 50        941     1400"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "earnings_cm = pd.DataFrame(confusion_matrix(y_true=y_test[\"income_bracket\"], \n",
    "                                           y_pred=baseline_rf_preds[\"class_pred\"]), \n",
    "                          columns=pd.Series([\"Under 50\", \"Over 50\"], dtype=\"category\"),\n",
    "                          index=pd.Series([\"Under 50\", \"Over 50\"], dtype=\"category\"))\n",
    "\n",
    "earnings_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the classification report seems to add more depth to the balance argument. Overall, the metrics seem balanced across all classes, though they are better for under 50 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.90      7428\n",
      "          1       0.69      0.60      0.64      2341\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test[\"income_bracket\"], baseline_rf_preds[\"class_pred\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test AUC score is also very impressive showing about .87. Given this is the baseline model, this seems to suggest the tuned models will be able to provide very good predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial random forest default model AUC: 0.8692\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial random forest default model AUC:\", \n",
    "      metrics.roc_auc_score(y_test[\"income_bracket\"], baseline_rf_preds[\"over_50_prob\"]).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into what might be driving this result, I've included the top 5 variables by importance here. Age appears as the most important. Putting them all together, my intuition is educated, older, and married individuals do better. The capital gains variable feels like it might be slight data leakage given this represents a tax from the sale of specific types of assets, including stocks, bonds, precious metals and real estate. Inherently, an individual needs a reasonable amount of money to make these types of sales so it's not surprising to see it as important for classifyig individuals who would make over 50K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>var_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.235792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hours_per_week</td>\n",
       "      <td>0.116604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capital_gain</td>\n",
       "      <td>0.099821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>marital_status_Married-civ-spouse</td>\n",
       "      <td>0.081542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>edu_years</td>\n",
       "      <td>0.064467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name  var_importance\n",
       "0                                 age        0.235792\n",
       "4                      hours_per_week        0.116604\n",
       "2                        capital_gain        0.099821\n",
       "32  marital_status_Married-civ-spouse        0.081542\n",
       "1                           edu_years        0.064467"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_importance =  pd.DataFrame({\n",
    "    \"name\": list(X_train.head(0)),\n",
    "    \"var_importance\": rf.feature_importances_}) \n",
    "\n",
    "var_importance.sort_values(by=[\"var_importance\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking on overfitting, it's not surprising to see such a high model accuracy and AUC. As I mentioned, the default tree setting has no max depth specified so it fits the data nearly perfectly creating the overfit model; that's sort of given with this baseline model. That said, the initial accuracy metrics in test are a reasonable starting point. A tuned model should show some evaluation metric increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98     17292\n",
      "          1       0.96      0.91      0.94      5500\n",
      "\n",
      "avg / total       0.97      0.97      0.97     22792\n",
      "\n",
      "Initial random forest default model training AUC: 0.9958\n"
     ]
    }
   ],
   "source": [
    "baseline_rf_train_preds = pd.DataFrame({\n",
    "    \"actual\": y_train[\"income_bracket\"],\n",
    "    \"class_pred\": rf.predict(X_train),\n",
    "    \"under_50_prob\": rf.predict_proba(X_train)[:,0],\n",
    "    \"over_50_prob\": rf.predict_proba(X_train)[:,1]\n",
    "})\n",
    "\n",
    "print(classification_report(y_train[\"income_bracket\"], baseline_rf_train_preds[\"class_pred\"]))\n",
    "print(\"Initial random forest default model training AUC:\", \n",
    "      metrics.roc_auc_score(y_train[\"income_bracket\"], baseline_rf_train_preds[\"over_50_prob\"]).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier with Grid Search\n",
    "\n",
    "With the baseline established, I'll work to develop some more tuned options. Starting this, I've included an AdaBoost model. It's being tuned with a grid search operation using ROC as the evaluation metric. Since I'll be constructing three tuned models with different search methods and parameters, I've developed a function that can accommodate the necessary customization and return the necessary evaluation objects, including reports and confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters from Grid Search:\n",
      "{'learning_rate': 1.2, 'n_estimators': 400, 'random_state': 1017}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def custom_tune(classifier, search, tune_params):\n",
    "    grid_search_model = search(classifier, tune_params, cv = 5, \n",
    "                               scoring = \"roc_auc\", refit = True, n_jobs = -1, verbose = 5)\n",
    "    grid_search_model.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    #developing predictions using model fit\n",
    "    grid_search_train_preds = pd.DataFrame({\n",
    "    \"actual\": y_train[\"income_bracket\"],\n",
    "    \"class_pred\": grid_search_model.best_estimator_.predict(X_train),\n",
    "    \"under_50_prob\": grid_search_model.best_estimator_.predict_proba(X_train)[:,0],\n",
    "    \"over_50_prob\": grid_search_model.best_estimator_.predict_proba(X_train)[:,1]\n",
    "    })\n",
    "    \n",
    "    grid_search_test_preds = pd.DataFrame({\n",
    "    \"actual\": y_test[\"income_bracket\"],\n",
    "    \"class_pred\": grid_search_model.best_estimator_.predict(X_test),\n",
    "    \"under_50_prob\": grid_search_model.best_estimator_.predict_proba(X_test)[:,0],\n",
    "    \"over_50_prob\": grid_search_model.best_estimator_.predict_proba(X_test)[:,1]\n",
    "    })\n",
    "    \n",
    "    #creating confusion matrix for preds\n",
    "    tuned_train_cm = pd.DataFrame(confusion_matrix(y_true=y_train[\"income_bracket\"], \n",
    "                                                           y_pred=grid_search_train_preds[\"class_pred\"]), \n",
    "                                          columns=pd.Series([\"Under 50\", \"Over 50\"], dtype=\"category\"),\n",
    "                                          index=pd.Series([\"Under 50\", \"Over 50\"], dtype=\"category\"))\n",
    "    \n",
    "    tuned_test_cm = pd.DataFrame(confusion_matrix(y_true=y_test[\"income_bracket\"], \n",
    "                                                           y_pred=grid_search_test_preds[\"class_pred\"]), \n",
    "                                          columns=pd.Series([\"Under 50\", \"Over 50\"], dtype=\"category\"),\n",
    "                                          index=pd.Series([\"Under 50\", \"Over 50\"], dtype=\"category\"))\n",
    "    \n",
    "    #creating classification reports\n",
    "    train_class_report = classification_report(y_train[\"income_bracket\"], \n",
    "                                               grid_search_train_preds[\"class_pred\"])\n",
    "    test_class_report = classification_report(y_test[\"income_bracket\"], \n",
    "                                              grid_search_test_preds[\"class_pred\"])\n",
    "    \n",
    "    #creating auc\n",
    "    train_auc = metrics.roc_auc_score(y_train[\"income_bracket\"], grid_search_train_preds[\"over_50_prob\"]).round(4)\n",
    "    test_auc = metrics.roc_auc_score(y_test[\"income_bracket\"], grid_search_test_preds[\"over_50_prob\"]).round(4)\n",
    "    \n",
    "    #creating feature importance\n",
    "    feature_importance = grid_search_model.best_estimator_.feature_importances_\n",
    "    \n",
    "    output = {\"test_cm\": tuned_test_cm,\n",
    "              \"train_cm\": tuned_train_cm,\n",
    "              \"test_report\": test_class_report,\n",
    "              \"train_report\": train_class_report,\n",
    "              \"test_auc\": test_auc,\n",
    "              \"train_auc\": train_auc,\n",
    "              \"test_results\": grid_search_test_preds,\n",
    "              \"feature_importance\": feature_importance\n",
    "              }\n",
    "    \n",
    "    print(\"Best model parameters from Grid Search:\")\n",
    "    print(grid_search_model.best_params_)\n",
    "    \n",
    "    \n",
    "    return(output)\n",
    "\n",
    "ada=AdaBoostClassifier(random_state=1017)\n",
    "\n",
    "ada_parameters = {\n",
    "    \"learning_rate\": [0.2, 0.4, 0.6, 0.8, 1,  1.2],\n",
    "    \"n_estimators\": [100, 200, 300, 400],\n",
    "    \"random_state\":[1017]\n",
    "}\n",
    "\n",
    "tuned_ada = custom_tune(classifier=ada, search=GridSearchCV, tune_params=ada_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the initial test confusion matrix shows a nice upgrade from the baseline random forest. The true negatives were 1400 in that model and have risen to 1509 here highlighting better predictive powers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Under 50</th>\n",
       "      <th>Over 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Under 50</th>\n",
       "      <td>6974</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Over 50</th>\n",
       "      <td>832</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Under 50  Over 50\n",
       "Under 50      6974      454\n",
       "Over 50        832     1509"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_ada[\"test_cm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report further bolsters this. The average metrics are each up 3 points from the random forest. This highlights that the tuning, and boosting model, seem to help improve the predictive work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.94      0.92      7428\n",
      "          1       0.77      0.64      0.70      2341\n",
      "\n",
      "avg / total       0.86      0.87      0.86      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tuned_ada[\"test_report\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final evaluation metric, the AdaBoost AUC is about .925, another increase from the original .869 from the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned AdaBoost model test AUC: 0.9252\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned AdaBoost model test AUC:\", tuned_ada[\"test_auc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction evaluation output for the fitted training values are found below. The results show the model is perhaps slightly overfit but, in general the evaluation metrics between train and test have been greatly reduced. For example, all the classification report average metrics are more or less equal while the AUC is also congruent. While there is still some generalization error gap, the overfitting has been diminished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Under 50</th>\n",
       "      <th>Over 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Under 50</th>\n",
       "      <td>16296</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Over 50</th>\n",
       "      <td>1911</td>\n",
       "      <td>3589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Under 50  Over 50\n",
       "Under 50     16296      996\n",
       "Over 50       1911     3589"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_ada[\"train_cm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.94      0.92     17292\n",
      "          1       0.78      0.65      0.71      5500\n",
      "\n",
      "avg / total       0.87      0.87      0.87     22792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tuned_ada[\"train_report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned AdaBoost model train AUC: 0.9312\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned AdaBoost model train AUC:\", tuned_ada[\"train_auc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 5 features here show some similarities with the random forest but, there are some differences. Now, both capital losses and gains are shown as being the top two predictors. Again, I think this makes intuitive sense given they're linked to transactions commonly linked to wealthier people. The other three were still identified by the the random forest, though not in the ranking order. Overall though, there is clear commonality between the model's on feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>var_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capital_gain</td>\n",
       "      <td>0.4125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capital_loss</td>\n",
       "      <td>0.1925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hours_per_week</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>edu_years</td>\n",
       "      <td>0.0150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  var_importance\n",
       "2    capital_gain          0.4125\n",
       "3    capital_loss          0.1925\n",
       "0             age          0.1100\n",
       "4  hours_per_week          0.0625\n",
       "1       edu_years          0.0150"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_ada_importance = pd.DataFrame({\n",
    "    \"name\": list(X_train.head(0)),\n",
    "    \"var_importance\": tuned_ada[\"feature_importance\"]\n",
    "})\n",
    "\n",
    "tuned_ada_importance.sort_values(by=[\"var_importance\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier with Grid Search\n",
    "\n",
    "The next model is a gradient boosting classifier constructed using grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters from Grid Search:\n",
      "{'learning_rate': 0.4, 'max_depth': 2, 'n_estimators': 400, 'random_state': 1017}\n"
     ]
    }
   ],
   "source": [
    "gbc=GradientBoostingClassifier(random_state=1017)\n",
    "\n",
    "gbc_parameters = {\n",
    "    \"max_depth\": [1, 2],\n",
    "    \"learning_rate\": [0.2, 0.4, 0.6],\n",
    "    \"n_estimators\": [100, 200, 300, 400],\n",
    "    \"random_state\":[1017]\n",
    "}\n",
    "\n",
    "tuned_gbc = custom_tune(classifier=gbc, search=GridSearchCV, tune_params=gbc_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial confusion matrix seems to highlight that GBM is slightly better than the Ada model. The report also shows the average metrics have improved slightly so I think this iteration is preferable to the Ada construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Under 50</th>\n",
       "      <th>Over 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Under 50</th>\n",
       "      <td>6991</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Over 50</th>\n",
       "      <td>828</td>\n",
       "      <td>1513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Under 50  Over 50\n",
       "Under 50      6991      437\n",
       "Over 50        828     1513"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_gbc[\"test_cm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.94      0.92      7428\n",
      "          1       0.78      0.65      0.71      2341\n",
      "\n",
      "avg / total       0.87      0.87      0.87      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tuned_gbc[\"test_report\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, the AUC has improved from .925 to .927."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Gradient Boost Classifier model test AUC: 0.9266\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned Gradient Boost Classifier model test AUC:\", tuned_gbc[\"test_auc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the Ada model, the overfitting here appears marginal. The train and test evaluation metrics are close, though no perfectly overlapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Under 50</th>\n",
       "      <th>Over 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Under 50</th>\n",
       "      <td>16425</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Over 50</th>\n",
       "      <td>1721</td>\n",
       "      <td>3779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Under 50  Over 50\n",
       "Under 50     16425      867\n",
       "Over 50       1721     3779"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_gbc[\"train_cm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.95      0.93     17292\n",
      "          1       0.81      0.69      0.74      5500\n",
      "\n",
      "avg / total       0.88      0.89      0.88     22792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tuned_gbc[\"train_report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Gradient Boost Classifier model train AUC: 0.9435\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned Gradient Boost Classifier model train AUC:\", tuned_gbc[\"train_auc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 5 features by variables by importance are the same as the Ada model but, in a different order. What's nice though is that the different model classes broadly align on the features given most of these have shown up across different options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>var_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.121181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capital_loss</td>\n",
       "      <td>0.109562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hours_per_week</td>\n",
       "      <td>0.104289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capital_gain</td>\n",
       "      <td>0.082247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>edu_years</td>\n",
       "      <td>0.058285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  var_importance\n",
       "0             age        0.121181\n",
       "3    capital_loss        0.109562\n",
       "4  hours_per_week        0.104289\n",
       "2    capital_gain        0.082247\n",
       "1       edu_years        0.058285"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_gbc_importance = pd.DataFrame({\n",
    "    \"name\": list(X_train.head(0)),\n",
    "    \"var_importance\": tuned_gbc[\"feature_importance\"]\n",
    "})\n",
    "\n",
    "tuned_gbc_importance.sort_values(by=[\"var_importance\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boosting (XGB) with Randomized CV Search\n",
    "\n",
    "The final construction here is an Extreme Gradient Boosting (XGB) with Randomized CV Search. The evaluation metrics highlight that it is the strongest option based on AUC. That said, it shows a slightly worse classification report than the GBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 13.0min finished\n",
      "C:\\Users\\Mark\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Mark\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters from Grid Search:\n",
      "{'n_estimators': 400, 'max_depth': 2, 'learning_rate:': 1.0, 'gamma': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "xgb=XGBClassifier(random_state=1017)\n",
    "\n",
    "xgb_parameters = {\"max_depth\": [1, 2],\n",
    "                  \"n_estimators\": list(range(100, 1000 + 1, 50)),\n",
    "                  \"learning_rate:\": np.linspace(0.1, 1.6, 17).round(1),\n",
    "                  \"gamma\": np.linspace(0, 5, 21)\n",
    "                 }\n",
    "\n",
    "tuned_xgb = custom_tune(classifier=xgb, search=RandomizedSearchCV, tune_params=xgb_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Under 50</th>\n",
       "      <th>Over 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Under 50</th>\n",
       "      <td>7030</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Over 50</th>\n",
       "      <td>884</td>\n",
       "      <td>1457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Under 50  Over 50\n",
       "Under 50      7030      398\n",
       "Over 50        884     1457"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_xgb[\"test_cm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.95      0.92      7428\n",
      "          1       0.79      0.62      0.69      2341\n",
      "\n",
      "avg / total       0.86      0.87      0.86      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tuned_xgb[\"test_report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Extreme Gradient Boost model test AUC: 0.927\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned Extreme Gradient Boost model test AUC:\", tuned_xgb[\"test_auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Under 50</th>\n",
       "      <th>Over 50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Under 50</th>\n",
       "      <td>16401</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Over 50</th>\n",
       "      <td>1959</td>\n",
       "      <td>3541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Under 50  Over 50\n",
       "Under 50     16401      891\n",
       "Over 50       1959     3541"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_xgb[\"train_cm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.95      0.92     17292\n",
      "          1       0.80      0.64      0.71      5500\n",
      "\n",
      "avg / total       0.87      0.87      0.87     22792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tuned_xgb[\"train_report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Extreme Gradient Boost model train AUC: 0.9316\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned Extreme Gradient Boost model train AUC:\", tuned_xgb[\"train_auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>var_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capital_gain</td>\n",
       "      <td>0.180438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capital_loss</td>\n",
       "      <td>0.128162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.124789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>edu_years</td>\n",
       "      <td>0.065767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hours_per_week</td>\n",
       "      <td>0.060708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  var_importance\n",
       "2    capital_gain        0.180438\n",
       "3    capital_loss        0.128162\n",
       "0             age        0.124789\n",
       "1       edu_years        0.065767\n",
       "4  hours_per_week        0.060708"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_xgb_importance = pd.DataFrame({\n",
    "    \"name\": list(X_train.head(0)),\n",
    "    \"var_importance\": tuned_xgb[\"feature_importance\"]\n",
    "})\n",
    "\n",
    "tuned_xgb_importance.sort_values(by=[\"var_importance\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Conceptual Questions\n",
    "\n",
    "#### In Ada Boost explain how the final predicted class is determined. Mark reference to the alpha parameter and explain what it represents.\n",
    "\n",
    "To begin, adaptive boosting, or Ada Boost, works by fitting numerous models sequentially on single predictors and combining weak learners (i.e. underfit models) to make stronger predictions as the ensemble progresses. This process ensures that hard cases are continually focused on. Formally, this happens by assigning weights to misclassified records, training a second model with updated weights from the first predictor and deriving predictions, and then updating weights again. This sequential, iterative process slowly updates before yielding final predictions. Once these ensemble of predictions are collected, the method, like bagging, are combined but, with these weights helping to determine the overall accuracy. The predicted class is the one that receives the majority of weighted votes.\n",
    "\n",
    "The alpha parameter is central to this process. The initial record weight is set to $\\frac{1}{m}$ and then updated once an error rate has been derived ($r_j$). Following this when the next predictor is used, an updated weight is calculated, and this is alpha ($\\alpha_j$). The alpha calculation takes into account the learning rate and $r_j$ to calculate a weight. The higher the value, the more accurate the prediction is and vice versa. With these, the final predictions can be made where each predictor is weighted using alpha.\n",
    "\n",
    "#### In Gradient Boosting, what is the role of the max_depth parameter? Why is it important to tune on this parameter?\n",
    "\n",
    "Max depth determines how deep a tree can grow. At larger values, the tree is larger exhibiting more splits. Inherently, this means that a larger tree fits the training data more closely. In gradient boosting, the idea is to limit max depth so grow shallow trees, which produce weak classifiers. Iteratively, these are used to update the ongoing predictions and taken together at the end as an ensemble. Additionally, the shallow tree depth also helps ensure the method is faster than developing a very deep random forest.\n",
    "\n",
    "#### In Part (e) of Steps 2-5 you determined the top 5 predictors across each model. Do any predictors show up in the top 5 predictors for all three models? If so, comment on if the predictor makes sense given what you are attempting to predict.\n",
    "\n",
    "I've put all five top predictors from each model into a common data frame so they can be reviewed in concert. I've included just the names to start but, the actual gini values are below as well. As seen, the top 5 predictors are common across all the models which have been tuned. However, the ordering is slightly different. For example, capital gains is the top predictor for ADA and XGB but, the fourth most important in GBC. The outlier here is the baseline random forest, which shows spouse as being in the top 5 in place of capital loss. Otherwise, the other four predictor are consistent with the tuned models.\n",
    "\n",
    "I think these all make sense intuitively. I've touched upon why capital gains and losses would be associated with making more than 50K per year. In realty, this might be a case of data leakage even though they aren't perfectly related. Hours per week and educational years also make sense given longer hours and higher attainment would generally be thought of as relevant to yearly earnings. Age also makes sense given older works, especially those with other factors like higher education, would be more advanced in their career and therefore, make more than 50K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ada_top_5</th>\n",
       "      <th>gbc_top_5</th>\n",
       "      <th>rf_top_5</th>\n",
       "      <th>xgb_top_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capital_gain</td>\n",
       "      <td>age</td>\n",
       "      <td>age</td>\n",
       "      <td>capital_gain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>capital_loss</td>\n",
       "      <td>capital_loss</td>\n",
       "      <td>hours_per_week</td>\n",
       "      <td>capital_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age</td>\n",
       "      <td>hours_per_week</td>\n",
       "      <td>capital_gain</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hours_per_week</td>\n",
       "      <td>capital_gain</td>\n",
       "      <td>marital_status_Married-civ-spouse</td>\n",
       "      <td>edu_years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>edu_years</td>\n",
       "      <td>edu_years</td>\n",
       "      <td>edu_years</td>\n",
       "      <td>hours_per_week</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ada_top_5       gbc_top_5                           rf_top_5  \\\n",
       "0    capital_gain             age                                age   \n",
       "1    capital_loss    capital_loss                     hours_per_week   \n",
       "2             age  hours_per_week                       capital_gain   \n",
       "3  hours_per_week    capital_gain  marital_status_Married-civ-spouse   \n",
       "4       edu_years       edu_years                          edu_years   \n",
       "\n",
       "        xgb_top_5  \n",
       "0    capital_gain  \n",
       "1    capital_loss  \n",
       "2             age  \n",
       "3       edu_years  \n",
       "4  hours_per_week  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"ada_top_5\": list(tuned_ada_importance.sort_values(by=[\"var_importance\"], ascending=False).head()[\"name\"]),\n",
    "    \"gbc_top_5\": list(tuned_gbc_importance.sort_values(by=[\"var_importance\"], ascending=False).head()[\"name\"]),\n",
    "    \"rf_top_5\": list(var_importance.sort_values(by=[\"var_importance\"], ascending=False).head()[\"name\"]),\n",
    "    \"xgb_top_5\": list(tuned_xgb_importance.sort_values(by=[\"var_importance\"], ascending=False).head()[\"name\"])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>name</th>\n",
       "      <th>var_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADA</td>\n",
       "      <td>capital_gain</td>\n",
       "      <td>0.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADA</td>\n",
       "      <td>capital_loss</td>\n",
       "      <td>0.192500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADA</td>\n",
       "      <td>age</td>\n",
       "      <td>0.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADA</td>\n",
       "      <td>hours_per_week</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADA</td>\n",
       "      <td>edu_years</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GBC</td>\n",
       "      <td>age</td>\n",
       "      <td>0.121181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GBC</td>\n",
       "      <td>capital_loss</td>\n",
       "      <td>0.109562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBC</td>\n",
       "      <td>hours_per_week</td>\n",
       "      <td>0.104289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GBC</td>\n",
       "      <td>capital_gain</td>\n",
       "      <td>0.082247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GBC</td>\n",
       "      <td>edu_years</td>\n",
       "      <td>0.058285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RF</td>\n",
       "      <td>age</td>\n",
       "      <td>0.235792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF</td>\n",
       "      <td>hours_per_week</td>\n",
       "      <td>0.116604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RF</td>\n",
       "      <td>capital_gain</td>\n",
       "      <td>0.099821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RF</td>\n",
       "      <td>marital_status_Married-civ-spouse</td>\n",
       "      <td>0.081542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RF</td>\n",
       "      <td>edu_years</td>\n",
       "      <td>0.064467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGB</td>\n",
       "      <td>capital_gain</td>\n",
       "      <td>0.180438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGB</td>\n",
       "      <td>capital_loss</td>\n",
       "      <td>0.128162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGB</td>\n",
       "      <td>age</td>\n",
       "      <td>0.124789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGB</td>\n",
       "      <td>edu_years</td>\n",
       "      <td>0.065767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGB</td>\n",
       "      <td>hours_per_week</td>\n",
       "      <td>0.060708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model                               name  var_importance\n",
       "0    ADA                       capital_gain        0.412500\n",
       "1    ADA                       capital_loss        0.192500\n",
       "2    ADA                                age        0.110000\n",
       "3    ADA                     hours_per_week        0.062500\n",
       "4    ADA                          edu_years        0.015000\n",
       "5    GBC                                age        0.121181\n",
       "6    GBC                       capital_loss        0.109562\n",
       "7    GBC                     hours_per_week        0.104289\n",
       "8    GBC                       capital_gain        0.082247\n",
       "9    GBC                          edu_years        0.058285\n",
       "10    RF                                age        0.235792\n",
       "11    RF                     hours_per_week        0.116604\n",
       "12    RF                       capital_gain        0.099821\n",
       "13    RF  marital_status_Married-civ-spouse        0.081542\n",
       "14    RF                          edu_years        0.064467\n",
       "15   XGB                       capital_gain        0.180438\n",
       "16   XGB                       capital_loss        0.128162\n",
       "17   XGB                                age        0.124789\n",
       "18   XGB                          edu_years        0.065767\n",
       "19   XGB                     hours_per_week        0.060708"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pd.DataFrame({\n",
    "    \"model\": pd.Series([\"ADA\", \"GBC\", \"RF\", \"XGB\"] * 5)\n",
    "}).sort_values(by=[\"model\"], ascending=True).reset_index(drop=True)\n",
    "\n",
    "top_five_predictors = pd.concat(\n",
    "    [tuned_ada_importance.sort_values(by=[\"var_importance\"], ascending=False).head(), \n",
    "     tuned_gbc_importance.sort_values(by=[\"var_importance\"], ascending=False).head(),\n",
    "     var_importance.sort_values(by=[\"var_importance\"], ascending=False).head(),\n",
    "     tuned_xgb_importance.sort_values(by=[\"var_importance\"], ascending=False).head()]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "pd.concat([model, top_five_predictors],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the models run in steps 2-5, which performs the best based on the Classification Report? Support your reasoning with evidence from your test data and be sure to share the optimal hyper parameters found from your grid search.\n",
    "\n",
    "The classification report highlights that GBC has the best evaluation metrics. This is seen given it has the highest average values across all three evaluation metrics. For comparison, I've included all four reports below which provides evidence of this. While the XGB model had a slightly higher AUC, the prediction accuracy is better for GBC so I'm carrying it forward as my preferred model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.90      7428\n",
      "          1       0.69      0.60      0.64      2341\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n",
      "ADA              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.94      0.92      7428\n",
      "          1       0.77      0.64      0.70      2341\n",
      "\n",
      "avg / total       0.86      0.87      0.86      9769\n",
      "\n",
      "Best model parameters from GBC: learning_rate: 0.4, max_depth: 2, n_estimators: 400, random_state: 1017 \n",
      "\n",
      "GBC              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.94      0.92      7428\n",
      "          1       0.78      0.65      0.71      2341\n",
      "\n",
      "avg / total       0.87      0.87      0.87      9769\n",
      "\n",
      "XGB              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.95      0.92      7428\n",
      "          1       0.79      0.62      0.69      2341\n",
      "\n",
      "avg / total       0.86      0.87      0.86      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RF\", classification_report(y_test[\"income_bracket\"], baseline_rf_preds[\"class_pred\"]))\n",
    "print(\"ADA\", tuned_ada[\"test_report\"])\n",
    "print(\"Best model parameters from GBC: learning_rate: 0.4, max_depth: 2, n_estimators: 400, random_state: 1017 \\n\")\n",
    "print(\"GBC\", tuned_gbc[\"test_report\"])\n",
    "print(\"XGB\", tuned_xgb[\"test_report\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For your best performing model, plot out an ROC curve using your test data. Describe what the x-axis & y-axis of the ROC curve tell us about a classifier.\n",
    "\n",
    "The ROC plot shows the false positive rate (x-axis) and the true positive rate (y-axis). The false positive rate reviews records that are actually negative but, are classified as positive. Essentially, this visualization helps highlight the review the sensitivity and specificity for a model. These are important for classification modelling as they provide an important visualization that accounts for various evaluation metrics simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2343cd16780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test[\"income_bracket\"],  tuned_gbc[\"test_results\"][\"over_50_prob\"])\n",
    "\n",
    "plt.figure(figsize = (12, 7))\n",
    "\n",
    "plt.plot(fpr, tpr, label = \"GBC ROC curve (AUC = %0.2f)\" % tuned_gbc[\"test_auc\"])\n",
    "plt.plot([0, 1], [0, 1], color = \"orange\")\n",
    "plt.legend(loc = 4)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "\n",
    "plt.title(\"ROC curve for Gradient Boosted Classifier model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Mark\\\\Machine Learning 5'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
